name: Data Processing Pipeline2

on:
  push:
    branches:
      - main  # Trigger workflow on push to the main branch

jobs:
  process-data:
    runs-on: [self-hosted, windows]  # Run this job on the self-hosted runner with Windows

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # Step 3: Install Jupyter and dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install jupyter pandas numpy  # Install jupyter and any other dependencies you need

      # Step 4: Run each Jupyter notebook for the respective steps
      - name: Run Notebook 1 - Quality Check
        run: |
          jupyter nbconvert --to notebook --inplace --execute notebooks/1_quality_check.ipynb

      - name: Run Notebook 2 - Preprocessing
        run: |
          jupyter nbconvert --to notebook --inplace --execute notebooks/2_preprocessing.ipynb

      - name: Run Notebook 3 - Feature Extraction
        run: |
          jupyter nbconvert --to notebook --inplace --execute notebooks/3_feature_extraction.ipynb

      - name: Run Notebook 4 - Anomaly Detection
        run: |
          jupyter nbconvert --to notebook --inplace --execute notebooks/4_anomaly_detection.ipynb

      - name: Run Notebook 5 - Save Results
        run: |
          jupyter nbconvert --to notebook --inplace --execute notebooks/5_save_results.ipynb

      # Step 5: Save processed data locally to the directory in your local machine
      - name: Save Processed Data Locally
        run: |
          echo "Saving files locally to C:/Pipeline/sensor-pipeline/data-pipeline-ci-cd/output_data"
          # Move files from the workflow output to the local directory on your machine
          move output_data/clean/* C:/Pipeline/sensor-pipeline/data-pipeline-ci-cd/output_data/clean/
          move output_data/corrupted/* C:/Pipeline/sensor-pipeline/data-pipeline-ci-cd/output_data/corrupted/
          echo "Files saved locally"

      # Step 6: Optionally, commit and push to GitHub from the local repository (manual step later)
      - name: Commit and Push Locally
        run: |
          git config --global user.name "Your Name"
          git config --global user.email "youremail@example.com"
          git add output_data/
          git commit -m "üîÅ Update processed output data"
          git push origin main  # Only if you want to push to the GitHub repository
